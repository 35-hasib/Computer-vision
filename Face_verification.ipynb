{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow keras dlib opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "\n",
    "# Load the pre-trained face detector and landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupported image type, must be 8bit gray or RGB image.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Error: Unable to load image. Check the file path.\")\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = detector(gray)\n",
    "    for face in faces:\n",
    "        # Get the landmarks/parts for the face\n",
    "        landmarks = predictor(gray, face)\n",
    "        \n",
    "        # Extract the coordinates of the 68 landmarks\n",
    "        landmarks_points = []\n",
    "        for n in range(0, 68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            landmarks_points.append((x, y))\n",
    "        \n",
    "        # Draw the landmarks on the image (optional)\n",
    "        for point in landmarks_points:\n",
    "            cv2.circle(image, point, 2, (255, 0, 0), -1)\n",
    "    \n",
    "    return landmarks_points, image\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    landmarks, image = preprocess_image(\"p11.jpeg\")\n",
    "    cv2.imshow(\"Image\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.24.99\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "print(dlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded successfully.\n",
      "Grayscale image type: uint8\n",
      "Grayscale image shape: (1214, 1214)\n",
      "Error during face detection: Unsupported image type, must be 8bit gray or RGB image.\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"p11.jpeg\")\n",
    "if image is None:\n",
    "    print(\"Error: Image not found or unable to load.\")\n",
    "else:\n",
    "    print(\"Image loaded successfully.\")\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    print(\"Grayscale image type:\", gray.dtype)  # Should be uint8\n",
    "    print(\"Grayscale image shape:\", gray.shape)  # Should be (height, width)\n",
    "\n",
    "    # Ensure the grayscale image is contiguous in memory\n",
    "    if not gray.flags['C_CONTIGUOUS']:\n",
    "        gray = np.ascontiguousarray(gray)\n",
    "\n",
    "    # Detect faces in the image\n",
    "    try:\n",
    "        faces = detector(gray)\n",
    "        print(f\"Number of faces detected: {len(faces)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during face detection: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unsupported image type, must be 8bit gray or RGB image.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m _, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     12\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m---> 14\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43mhog_face_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m faces:\n\u001b[0;32m     17\u001b[0m     face_landmarks \u001b[38;5;241m=\u001b[39m dlib_facelandmark(gray, face)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unsupported image type, must be 8bit gray or RGB image."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "hog_face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "dlib_facelandmark = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = hog_face_detector(gray)\n",
    "    for face in faces:\n",
    "\n",
    "        face_landmarks = dlib_facelandmark(gray, face)\n",
    "\n",
    "        for n in range(0, 16):\n",
    "            x = face_landmarks.part(n).x\n",
    "            y = face_landmarks.part(n).y\n",
    "            cv2.circle(frame, (x, y), 1, (0, 255, 255), 1)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Face Landmarks\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
